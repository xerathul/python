{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf31cnn_mnist_subclassing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBlGswtYi5qA6owhe39Psg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xerathul/python/blob/master/tf31cnn_mnist_subclassing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79N9_JA3-ALb",
        "outputId": "5ed96947-441e-427b-afdf-49bc076dc0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "# CNN : 이미지의 특징을 뽑아 크기를 줄인 후 마지막에 1차원 배열로 만든 후 Dense에게 전달하는 방식\n",
        "# MNIST dataset을 사용\n",
        "# subclassing model api 방법\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from keras import datasets, Model\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "train_images = x_train.reshape((60000, 28, 28, 1))\n",
        "train_images =  train_images / 255.0\n",
        "test_images = x_test.reshape((10000, 28, 28, 1))\n",
        "test_images =  test_images / 255.0\n",
        "train_labels = y_train\n",
        "test_labels = y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data.Dataset.from_tensor_slices() : 입력 파이프라인을 가능하게 함. 데이터를 골고루 섞기 등의 작업이 가능\n",
        "# Dataset.from_tensor_slices() 경험해 보기 ----------\n",
        "import numpy as np\n",
        "x = np.random.sample((5, 2))\n",
        "print(x)\n",
        "dset = tf.data.Dataset.from_tensor_slices(x)\n",
        "print(dset)\n",
        "dset = tf.data.Dataset.from_tensor_slices(x).shuffle(10000).batch(3)\n",
        "print(dset)\n",
        "for a in dset:\n",
        "    print(a)\n",
        "# ---------------------------------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQt7r40s_Gp0",
        "outputId": "92b20f47-609d-4ace-c0b5-52bfceeac783"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.08050424 0.44565513]\n",
            " [0.41209626 0.74065825]\n",
            " [0.92934785 0.95255907]\n",
            " [0.26258291 0.58926741]\n",
            " [0.78936217 0.09917395]]\n",
            "<TensorSliceDataset element_spec=TensorSpec(shape=(2,), dtype=tf.float64, name=None)>\n",
            "<BatchDataset element_spec=TensorSpec(shape=(None, 2), dtype=tf.float64, name=None)>\n",
            "tf.Tensor(\n",
            "[[0.92934785 0.95255907]\n",
            " [0.41209626 0.74065825]\n",
            " [0.08050424 0.44565513]], shape=(3, 2), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[0.78936217 0.09917395]\n",
            " [0.26258291 0.58926741]], shape=(2, 2), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST의 학습 데이터(60000, 28, 28)가 입력되면 6만 개의 slice를 만들고 각 slice는 28 * 28 형태로 만들기\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).batch(28)\n",
        "print(train_ds)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(28)\n",
        "print(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3BUGR8kCiBh",
        "outputId": "8826642e-0422-4378-be3a-17e782372de2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subclassing model\n",
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv2D(filters=32, kernel_size=[3,3], padding='valid', activation='relu')\n",
        "        self.pool1 = MaxPool2D((2,2))\n",
        "        self.conv2 = Conv2D(filters=32, kernel_size=[3,3], padding='valid', activation='relu')\n",
        "        self.pool2 = MaxPool2D((2,2))\n",
        "        self.flatten = Flatten(dtype='float32')\n",
        "        self.d1 = Dense(32, activation='relu')\n",
        "        self.drop1 = Dropout(rate=0.2)\n",
        "        self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.pool1(net)\n",
        "        net = self.conv2(net)\n",
        "        net = self.pool2(net)\n",
        "        net = self.flatten(net)\n",
        "        net = self.d1(net)\n",
        "        net = self.drop1(net)\n",
        "        net = self.d2(net)\n",
        "        return net\n",
        "\n",
        "model = MyModel()\n",
        "temp_inputs = tf.keras.Input(shape = (28, 28, 1))\n",
        "model(temp_inputs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM2V2pCJETBv",
        "outputId": "29a93ade-cdca-4bf6-9424-37bc545b4c0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'my_model_1')>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, batch_size=128, epochs=5, verbose=2, \n",
        "          use_multiprocessing=True, workers=2)\n",
        "score = model.evaluate(test_images, test_labels)\n",
        "print('loss : ', score[0])\n",
        "print('acc : ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq5rAF9cEkzt",
        "outputId": "d352d7bd-ec24-453a-9abd-8f53399765c3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 - 13s - loss: 0.4579 - accuracy: 0.8579 - 13s/epoch - 28ms/step\n",
            "Epoch 2/5\n",
            "469/469 - 2s - loss: 0.1642 - accuracy: 0.9492 - 2s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "469/469 - 2s - loss: 0.1242 - accuracy: 0.9618 - 2s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "469/469 - 2s - loss: 0.1043 - accuracy: 0.9682 - 2s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "469/469 - 2s - loss: 0.0900 - accuracy: 0.9722 - 2s/epoch - 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9863\n",
            "loss :  0.03949269279837608\n",
            "acc :  0.986299991607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KfiOkIUNLdrL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}